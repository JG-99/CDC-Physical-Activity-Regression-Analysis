---
title: "STAT 350 - Project"
date: "11/21/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#loading libraries
library(tidyverse)
library(ggpubr)
library(caret)
library(faraway)
library(usmap)
```




# Data Cleaning

```{r}
#This section of code loads in the data, deletes columns with extraeous information, and filters the data to Obesity/Weight Status

#loading data
data <- read.csv("nutrition_data.csv", header = TRUE,na.strings=c("","NA"))
min(data$YearEnd)
#Removing Redundant Columns
summary(data)
# Delete Location Desc - LocationAbbr is the same column
# Delete Datasource - All Data comes from the same location
# Delete Topic - Same information As Class
# Delete Data_value_Unit & Data_Value_Type - Unit is all NA and All the data is a value of a type
# Delete Data_Value_Alt - Same information as Data_Value
# Delete Data_Value_FootNote_Symbol & Data_Value_Footnote - Provides information about missing samples
# Delete Total - Adds in no information
# Delete ClassID, TopicID, QUestionID, DataValueTypeID, LocationID, StratificationCategoryID1, StratificationID1
# Delete Low_Confidence_Limit, High_Confidence_Limit, Sample Size - calulated confidence intervals for each sample size


#deleting redundant values
data <-  data %>% select(-c(LocationAbbr,Datasource, Topic,Data_Value_Unit,Data_Value_Type,Data_Value_Alt,Data_Value_Footnote,Data_Value_Footnote_Symbol, Total, ClassID, TopicID, Data_Value_Unit, QuestionID, DataValueTypeID, LocationID, StratificationCategory1, StratificationCategoryId1,Stratification1, StratificationID1))

#Filtering the Data to focus on A SPECIFIC QUESTION, OVERWEIGHT IS REMOVED
summary(data$Class)
data <- data %>% filter(Class == "Physical Activity" & Question == "Percent of adults who engage in muscle-strengthening activities on 2 or more days a week") %>% select(-c(Question, Class))

#Checking for length of study (YearEnd - YearStart) to see if there's studies crossing multiple years
data %>% filter( YearEnd - YearStart > 0)
data <- data %>% select(-YearEnd)

#Removes Confidence Interval + Sample Size + Geolocation
data <- data %>% select(-c("Low_Confidence_Limit","High_Confidence_Limit","Sample_Size", "GeoLocation"))

#filtering to view age + filtering null GeoLocation Values
data <- data %>% filter(!as.character(LocationDesc) %in% c("National","Guam","Puerto Rico"), !is.na(Age.years.)) %>% select(-c(Education, Gender, Income, Race.Ethnicity))

#checks if there's any more missing values
summary(!is.na(data))
data <- droplevels(data)

head(data)
```



# Data Description & visualization

```{r}
#Introducing a new value
data %>% filter(YearStart == 2011, LocationDesc == "Alabama",Age.years. == "18 - 24")

new_point <- data.frame(YearStart = 2011,LocationDesc = factor("Alabama"),Data_Value = 60, Age.years. = factor("18 - 24"))
data <- rbind(data,new_point)

```



```{r}
#Data Visualization - Distribution
yeardist <- data %>% ggplot(aes(x = YearStart)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("YearStart") + ylab("Count") + ggtitle("Distribution of Surveys \n from 2011 - 2015")

locdist <- data %>% ggplot(aes(x = LocationDesc)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("LocationDesc") + ylab("Count")  + ggtitle("Distribution of Surveys in US States/Districts")

agedist <- data %>% ggplot(aes(x = Age.years.)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Age.years.") + ylab("Count") + ggtitle("Distribution of Surveys \n in each Age Group")

ydist <- data %>% ggplot(aes(x = Data_Value)) + geom_density()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Proportion") + ylab("Density") + ggtitle("Density of Proportion")


ggarrange(locdist,
          ggarrange(agedist,yeardist,ydist, ncol = 3),
          nrow = 2)
#ggsave("Plots/distribution.png", width = 7, height = 7)     
```


```{r}
#Data Visualization

# Year vs Work Out Rate
yearbox <- data %>% group_by(YearStart) %>% mutate(median_value = median(Data_Value)) %>% ggplot(aes(x = reorder(YearStart,median_value), y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Year") + ylab("Proportion") + ggtitle("Proportion for All Years")

# Age Group vs Work out Rate
agebox <- data %>% group_by(Age.years.) %>%  ggplot(aes(x = Age.years., y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Age Grouping") + ylab("Proportion") + ggtitle("Proportion for All Age Groups")

# State vs Work Out Rate
locbox <- data %>% group_by(LocationDesc) %>% mutate(median_value = median(Data_Value)) %>% ggplot(aes(x = reorder(LocationDesc,median_value), y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("State/District") + ylab("Proportion") + ggtitle("Proportion for All US States/Districts")

# Heatmap of states
data_temp <- data %>% rename("state" = "LocationDesc")
plot_usmap(data = data_temp, values = "Data_Value", color = "red", labels = TRUE) + scale_fill_continuous(name = "Proportion", label = scales::comma) + labs( title = "Heatmap of Proportions for US States/Districts" )


#pairs plot for correlation
pairs(data, main = "Pairs Plot of Explanatory and Response Variables")

ggarrange(yearbox, agebox,
          ggarrange(locbox, ncol = 1),
          ncol = 1, nrow = 3, widths = 7, heights = 100)
#ggsave("Plots/exploratory_analysis.png", width = 7, height = 7)  
```


# Methods
```{r}
# Train/Test Split (80/20)
head(data)
set.seed(2928820)
test.size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = test.size)

data.train <- data[train_ind,]
data.test <- data[-train_ind,]

row.names(data.train) <- NULL
rownames(data.test) <- NULL

data.train %>% filter(LocationDesc == "Alabama", Data_Value >= 60)
```




```{r}
# Hypothesis testing - Model Building

#linear regression - no interaction
train.lm <- lm(Data_Value ~., data.train)

train.lm.noyears <- lm(Data_Value ~ LocationDesc + Age.years., data.train)

#interaction Model on Age
train.lm.age <- lm(Data_Value ~  YearStart*Age.years. + LocationDesc, data.train)

#interaction Model on Location
train.lm.loc <- lm(Data_Value ~  YearStart*LocationDesc + Age.years., data.train)

#interaction model on all 
train.lm.all <- lm(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, data.train)

```






```{r}
#Hypothesis Testing - Interaction on age
anova(train.lm,train.lm.age)

```



```{r}
#Hypothesis Testing - Interaction on location
anova(train.lm, train.lm.loc)

```



```{r}
#Hypothesis Testing - Interaction on All
anova(train.lm.age, train.lm.all)

```


```{r}
#Model Selection using AIC
AIC(train.lm, train.lm.age,train.lm.loc, train.lm.all)

```

# Model Building and Selection


```{r}
# Model Selection - Building Models

#10 fold cross validation for comparision
control <- trainControl(method = "cv", number = 10,returnResamp="all")

#linear regression - no interaction
set.seed(2928820)
mod.lm <- train(Data_Value ~ ., method = "lm", trControl = control, data.train)
mod.lm.RMSE <- mod.lm$resample[,"RMSE"]
mod.lm.r2 <- mod.lm$resample[,"Rsquared"]

#Stepwise regression w/ BIC - no interaction
set.seed(2928820)
mod.step <- train(Data_Value ~., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.RMSE <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"RMSE"]
mod.step.r2 <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"Rsquared"]

## MODELS WITH 1 INTERACTION

#linear Regression - interaction on Age years
set.seed(22928820)
mod.lm.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.age.RMSE <- mod.lm.age$resample[,"RMSE"]
mod.lm.age.r2 <- mod.lm.age$resample[,"Rsquared"]

#linear Regression - interaction on LocationDesc
set.seed(2928820)
mod.lm.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "lm", trControl = control, data.train)
mod.lm.loc.RMSE <- mod.lm.loc$resample[,"RMSE"]
mod.lm.loc.r2 <- mod.lm.loc$resample[,"Rsquared"]

#Stepwise regression w/ BIC - interaction on Age years
set.seed(2928820)
mod.step.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.age.RMSE <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"RMSE"]
mod.step.age.r2 <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"Rsquared"]

#Stepwise regression w/ BIC - interaction on LocationDesc
set.seed(2928820)
mod.step.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.loc.RMSE <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"RMSE"]
mod.step.loc.r2 <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"Rsquared"]



##MODELS WITH ALL INTERACTION TERMS

#linear Regression - all interaction
set.seed(2928820)
mod.lm.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.intr.RMSE <- mod.lm.intr$resample[,"RMSE"]
mod.lm.intr.r2 <- mod.lm.intr$resample[,"Rsquared"]

#Stepwise regression w/ all interaction
set.seed(2928820)
mod.step.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.intr.RMSE <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"RMSE"]
mod.step.intr.r2 <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"Rsquared"]

```



```{r}
#Model Selection - Comparing Models

#Collecting the Errors
rMSPE <- as.matrix(cbind(mod.lm.RMSE, mod.lm.age.RMSE,mod.lm.loc.RMSE,mod.lm.intr.RMSE, mod.step.RMSE, mod.step.age.RMSE,mod.step.loc.RMSE,mod.step.intr.RMSE))
r2 <- as.matrix(cbind(mod.lm.r2, mod.lm.age.r2,mod.lm.loc.r2,mod.lm.intr.r2, mod.step.r2, mod.step.age.r2,mod.step.loc.r2,mod.step.intr.r2))

colnames(rMSPE) <- substr(colnames(rMSPE),5,nchar(colnames(rMSPE)) - 5)
colnames(r2) <- substr(colnames(r2),5,nchar(colnames(r2)) - 3)

mins.MSPE <- apply(rMSPE,1,min)
mins.r2 <- apply(r2,1,max)

#visualizations
par(mfrow = c(1,2))
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV", xlab = "model", ylab = "root-MSPE")
#boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV",xlab = "model", ylab = "Relative root-MSPE")
boxplot(r2, las = 2, main = "R2 from 10-Fold CV", xlab = "model", ylab = "R2")


## All of the LM models perform decently well
```



```{r}
## RESULTS

mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)

mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)

pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
              ,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
              ,mod.step.intr.pred)


calculateMSPE <- function(mod,test){
  result <- matrix(nrow = 1, ncol = ncol(mod))
  colnames(result) <- colnames(mod)
  for(i in 1:ncol(mod)){
    result[i] <- mean((test$Data_Value - mod[,i])^2)  
  }
  result
}

calculateR2 <- function(mod,test){
  result <- matrix(nrow = 1, ncol = ncol(mod))
  colnames(result) <- colnames(mod)
  for(i in 1:ncol(mod)){
    result[i] <- cor(mod[,i],test$Data_Value)^2
  }
  result
}


MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.pred, xlab = "Observed Value", ylab = "Predicted Value", main = "Predicted vs Observed Value")
abline(c(0,1))

```


#Residual Analysis 

```{r}
summary(mod.lm$finalModel)

```

```{r}
#Residual Analysis
par(mfrow = c(2,2))
plot(mod.lm$finalModel)
#Checking assumptions of linear Regression
#1-Independence of observations is assumed 
#2-Linearity is satisfied from the given q-q plot
#3-Normality is confirmed due to distribution of the residual in Histogram
#4-heteroscedasticity is true since median is centered around 0 and distribution around it is pretty even
```


```{r}
vif(mod.lm$finalModel)
#VIF values are all below 5 so we know there is no multicolinarity problems in the dataset
```




```{r}
#Check for influential points
cooksd <- cooks.distance(mod.lm$finalModel)
which(cooksd > 1)
```

```{r}
#leverage points

#High H_ii values
H <- diag(lm.influence(mod.lm$finalModel)$hat)
p <- length(mod.lm$finalModel$coefficients)

2*p/nrow(data.train)


which(H > 2*p/nrow(data.train), arr.ind = TRUE)

#Large Residuals

student.resid <- rstudent(mod.lm$finalModel)
which(abs(student.resid) >= 3)



```







